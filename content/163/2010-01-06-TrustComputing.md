Comments: true
Date: 2010-01-06 00:00:00
Layout: post
Slug: 57
Title: TrustComputing
Wordpress_id: 57
Category: Nonsense
TrustComputing

  


（未写完）硕士阶段选方向，说让选可信计算或普适计算，虽说两个都不熟，但想着后者比较虚，前者好歹还能算一算，自己向来是对计算比较擅长和感兴趣，于是就选作可信计算了，洋文就叫Trust Computing。由于比较懒的缘故吧，没搞出什么东西来，不过照例还是有些古怪的想法，于是想拿来写写，就当练练笔也好。  
（声明，这个不是什么论文，也不是什么报告，纯粹是随兴之作，哪边逻辑跳了，或者是瞎扯了，大家不要笑。扯蛋么，就是要扯的乱七八糟的才有意思。）  
背景  
一 学术方面  
首先谈谈正统的Trust Computing。从咱看的几十篇文章（好像是少了点）来看， Trust Computing的发展主要分为两条线：一是80年代英国帝国大学的某人（记不清了）的博士论文首先介绍了在Agent的使用中引入trust的概念来解决Agent在陌生环境下的行为决策问题，这应该算是Trust这一概念在计算机行业中的首次引入，这一条线上的中心是如何把社会学科中的“信任”来找到计算机中的对应物，从而在此基础上能得到一些应用。随着接下来的90年代计算机网络和agent技术的发展，一部分学者在trust上展开了研究，但搞来搞去，对Trust如何去定义还是没有什么定论，缺乏权威级的著作，因此慢慢的就淡下去了。第二条线是21世纪初，以M Blaze为代表的几个人做了几个信任推导的系统，本质上其实就是传统授权系统的分布式扩展，在最初几年还是受到了广泛的关注，老板说他的博士论文的idea就是源于此，因此我们组也算是要挂在这条线下吧。这第二条线主要是从传统的计算机技术加以改进，再从概念上往trust方面靠，来寻求一个解释，因而算是跟第一条线走的相反的方向，不过老实说，在抽象层次和思想的创新度和成熟度上还是要相对差一些，不过由于环境的缘故，即我们的网络环境益发变的脆弱不堪，良好的安全保障机制又基本等于无的情况下，第二条线为代表的与网络安全息息相关的trust技术就显得很有市场，于是也算火了几年，但和之前关于trust的研究一样，在基础概念上仍然无法达到共识，甚至可以说无法达到一个较为准确、全面的定义，大家都喜欢自说自话，把信任的定义往自己的应用上去靠，而不是基于信任的定义来指导自己的应用，因而弄出来的成果在科学性和普适性上都要大打问号，因此渐渐也搞不下去了，包括领军的那几位也转移阵地了，所以可信计算在这边就渐渐显得冷清起来。不过此伏彼起的是，第一条线上的研究却进入了一个新的高潮，这主要是源于欧洲的一个叫SECURE（这是缩写，详细的请google）项目，算是聚集了很多一部分人，主要是英联邦的一些学者来对trust computing进行研究，做了很多项目，也对基础理论进行了很多探索，虽说依然无法对“Trust”给出一个最佳的定义，但至少在概念上形成了一个比较大范围上的共识，也把trust computing 的身形渐渐勾勒出来。




二 企业方面  
扯完学术方面的，再来谈谈工业界的，这跟我们的实际生活联系的更紧密些。正如大家所知道的那样，自由和纪律是DNA式的双螺旋结构，两者是看似矛盾，确是互相依赖，相辅相成的好哥俩。如今的计算机技术的发展对社会带来的一个最重要的影响，就是造就了自由度史无前例高的虚拟社会，然而在纪律约束方面还远远没有跟上，于是这个虚拟社会在快速膨胀的过程中，安全性、可靠性等方面也饱受着无序的困扰。因此，凡是能解决这个问题的方法和技术，都自然会得到追捧，Trust Computing就首当其冲。在硬件方面，出现了可信计算基这样的基础设施上的研究，还有cpu里面好像也有相应的技术在发展，另外指纹识别、加密狗等设备也可以涵括在trust Computing范围中；软件方面，直接摆在台面上的，就包括比尔盖茨大概在03年左右就在谈可信计算，最近两年好像又吹了几次，可见其分量，而不是那么显眼的，就包括了电子商务网站的一些评分机制，比如ebay，淘宝，amazon，这些评分机制虽然简单，但却极其有用，虽说在学术论文里向来作为横向比较的标杆，就像ie6在浏览器测试中的地位一样，但正是由于其简洁性和通用性，因此依然是用的最广和最久的，这可能又是一个“简单的就是最好的”这一信条的极好的例子，当然，在这些评分机制之外还有一些变种，包括各大论坛的会员等级制度，等等等等。可见，Trust Computing在工业界发展的也是如火如荼，不过跟其在学术界的混乱一样，工业界的相关技术也都是零零散散的，很难统一到一个确定无歧义的框架或是概念中去，这也就为其之后的发展带来了障碍。

定义  
刚刚瞎扯了一通，但是概念上还没涉及，因此估计看得会晕晕乎乎的，写的也是别别扭扭的。这里就阐述一下我对Trust Computing的个人理解吧。  
Trust Computing，国内译作可信计算。但我觉得这个翻译很糟糕。  
首先直接从字面上看，可信计算倒过去翻，应该叫做Trustable Computing，这就显出翻译的牵强之处了。  
其次从范围上来说，Trust Computing，强调的是利用Trust 来作为Computing的基础，因而是一种内涵性的表述，而可信计算，不仅翻过来变味了，在国内的研究重点上，也是围绕在如何让软件具备高可靠性这一点上进行研究，因而是个外延性的概念，在深度上来说前者更有意义和科学性，而后者更加泛泛，也更好骗国家钱。  
我们再拿“Trust Computing”来细说说，这个词组，拆开来，就是Trust和Computing。对于Trust来说，现在比较倾向的一种说法是用概率来解释，当然是个什么样的概率（通俗点讲，用哪个去除哪个）就有很多说法了，不过本质上都一样，虽说都是作为概率去表现，但如何去理解Trust还是比较费脑筋的，恰巧看到一篇德国的哲学文章，里面的定义还算对胃口：“信任就是一种知识的弱的归纳形式”，这个定义就切中了要害，我们平常所感知的信任是什么？其实就是我们过去所有经验，相关知识，以及对当前环境认知等种种信息糅合而成的一个模糊的概念，是各种零散的知识的一个提炼，所以说Trust的本质是知识，只是这个知识是提炼后得到的，代表了所有相关的原始的知识。现有的Trust Computing中对Trust的建模，差不多都是这个意思，虽然表面上这个是一维的，那个是二维的，但这也只是提炼程度的差别而已了。正是由于Trust的广泛性和非原生性的特点，所以导致很难对它进行定义和建模，这也就是为什么到现在学术界对Trust的定义仍然这么混乱的原因了（通常所说的跨学科，跨场景都只是些表面原因）。  
Trust是“Trust Computing”中的核心部分，是“静”的那一半，光有个概念，光光能对其建模（当然就这一点来说，目前还差的比较多）是远远不够的，还需要能以这种初步提炼的知识为基础，来动态持续的产生些新的知识，才真真的算作有价值，这也就是我们通常所说的Computing。而谈到Computing，就不得不谈谈现在的一个怪现象，那就是举凡作了点东西，都喜欢在屁股后面加个计算两字，方能显得高深、科学、牛逼，比如说网格计算啊，可信计算啊，双向计算啊，普适计算啊。。。。。。，好多好多，但这其中能担得起“计算”盛名的恐怕只有少数，大部分都是滥竽充数的，或者是套了马甲的，虽然按广义的观点来看，这些也都是利用一定的规则来对预定义的一些常识进行推理运算，自成体系，应该可以叫做“计算”啊。但我总觉的“计算”这个词是一个高贵的词，不在概念的深刻性和范围的通用性上都比较出色的概念最好不要硬跟他扯上关系，像“爷们”这个词，你不能按照最广义的解释去定义他，就像你称小沈阳是爷们就会觉得侮辱这个词了，而随便加“计算”的话，也会有种亵渎的感觉。跑的有些远，我们回来谈谈对Trust的computing，鉴于现在对Trust的定义的混乱，那么对基于其得computing的研究更是乏善可陈了，不过总结起来有这么两条：一是加权平均，别看这方法简单，但他确实有效，所以大家也用的做多，不过因为没有很好的理论基础，所以很难对其进行解释，而且这种计算是一次性的，很难以产生的知识作为输入进行再计算，因此，这种方法在Trust Computing研究的初期还能谈谈，而要想深入研究的话，就显得太naive了；二是穷举，表现在算法上是穷举，在实现中往往是泛洪，这种技术是要求搜索所有相关(至少是大部分)知识来做推导，早期就是用些推导规则，后期就套上个本体的壳，不过冷静点想的话，这种是基本没有实用价值的，而且本质上应该归属于传统“硬计算”的范畴，即所有相联系的对象和环境都要预确定，而Trust Computing本就是用来针对有现实社会的复杂性所带来的不确定性的，因而应该是一种带有模糊性和盲目性的“软计算”，所以说这种方法天生就不是用来computing trust的料。当然，在trust computing的研究中也有一些不错的成果，其中我觉得josang提出的主观逻辑还是很有些道理，虽然他的理论还有些瑕疵，但总的来说应该是正确的，有着良好的数学基础，并且通用程度上也不错，如果在这上面多做些内容的话，应当能有些发现，不过我在读研的时候已经渐渐失去了做学术的耐心（或者说根本没有过），所以就作为遗留物扔那了，后期好像有个师弟会再去看看，不知道还有什么成果。  
总之，我认为Trust Computing应该就是要找到一种科学的计算系统来对现有生活中的各种知识进行建模和运算，来产生一些更凝练，更有价值的新知识，来方便我们再复杂的、难以预料的环境中生存下去。从这个角度上看，它和数据挖掘似乎更接近，区别在于后者往往通过统计的方式来达到目的，更关注结果。而前者还是希望先建立一套可解释的理论系统，并以此为基础，因此比较侧重于过程。

特征

上一部分主要谈及的是关于Trust Computing内涵方面的观点，而在外延方面，主要是在呈现特征方面，也有一些东西可以谈谈。  
模糊性。正是由于trust本身是一种归纳性知识的特点，造成其会有信息的丢失，因而是一种模糊的概念，那么在其之上的trust computing得到的结果也必然是模糊的。所以说如果你用精确的手段去衡量Trust computing的话，就只有两种可能了，一是结论本身就不对，二是即使对，也只能适用在一个特定的环境里面。虽然模糊性看起来好像是有点不靠谱，但其确是最实际的，而且也是目前甚至将来计算机技术发展比较容易有成果的一个方面。不过要模糊的好也比较困难，关键是要有坚实的理论基础，在这方面，主要是依靠概率论，而模糊数学和主管逻辑也是可以借鉴的两个重要的理论。  
协作性。前面谈到过可信计算和数据挖掘具有相似性，其中一个方面就是为了产生一个很小的结论，都需要消耗掉大量的信息。这在当前的环境中，往往是很难达到的，毕竟一个人的精力和经历都比较有限，这时就需要整个社会的相互协作了。可以预计，可信计算将会把人类的社会性推到一个前所未有的高度中去。  
适应性（前进性）。可信计算无疑将是近后计算机技术的核心部分，作为一个长期并且关键的部分，自然是要有能不断演进的能力，当然这个特性显得就不那么突出了，因为现在很多人都在大谈特谈自适应什么的，不过好像没几个人真正懂“适应性”这个词的概念。  
应激性（快速反应能力）。这个特性将会越来越受到重视，我最初有这个概念的时候，是唯一的一次有大老板参加的讨论会（记得是研一下半学期伊始，当时还算比较上进的，去听讲座），当时有个“emergency”的词大家不会翻；后来在a system of patterns上又见到这个词；然后在邮件列表里看到kent beck提到反应式设计的概念，虽然没在跟进去探究，但估计概念上不会有太大差别。可见，应激性这个特征还是有很多人关注的，而愚见是它将成为今后人们研究的一个热点。  
扯得太多，自己也晕了，就到此为止了。

展望  


这边就简单说两句了。Trust computing在未来的日子里显然将会越来越重要，发展的也会越来越红火，它带给我们的会是一种观念上的一种革新，并且这种变革最终会体现到我们的生活中去。这里值得一提的是，trust computing与现在炒的正热的云计算其实又很大一部分重叠，甚至可以说两者是一体的，只是前者更多的从数学本质上来说，而后者的名称更强调一种表现形式。  


[原文链接](http://lw02nju.blog.163.com/blog/static/111602792009112711424381/)
